% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/EPSGO.R
\name{epsgo}
\alias{epsgo}
\title{Efficient Parameter Selection via Global Optimization}
\usage{
epsgo(Q.func, bounds, x, y, family = "gaussian", lambda = NULL,
  p = NULL, intercept = TRUE, foldid = NULL, num.nonpen = 0,
  strata.surv = NULL, threshold = 0, standardize.response = FALSE,
  round.n = 5, parms.coding = "none", fminlower = 0,
  flag.find.one.min = FALSE, show = "none", N = NULL,
  maxevals = 500, constantMean = 0, epsilon = 1e-04,
  Dir.ep = 1e-04, Dir.tol = 0.01, EI.eps = 0.01, min.iter = 10,
  pdf.name = NULL, pdf.width = 12, pdf.height = 12, my.mfrow = c(1,
  1), parallel = FALSE, modelList = NULL, verbose = TRUE,
  seed = 123, search.path = FALSE, ...)
}
\arguments{
\item{Q.func}{name of the function to be minimized.}

\item{bounds}{bounds for the interval-searching parameters}

\item{x, y}{input matrix.}

\item{family}{response type.}

\item{lambda}{optional user-supplied \code{lambda} sequence; default is NULL, and \code{espsgo} chooses its own sequence.}

\item{p}{the number of predictors from different data source.}

\item{intercept}{should  intercept(s) be fitted (default=\code{TRUE}) or set to zero (\code{FALSE}).}

\item{foldid}{an vector of values for the cross-validation.}

\item{num.nonpen}{number of predictors forced to be estimated (i.e., nonpenalization).}

\item{strata.surv}{stratification variable for the Cox survival model.}

\item{threshold}{threshold for estimated coefficients of the tree-lasso models.}

\item{standardize.response}{standardization for the response variables. Default: \code{TRUE}.}

\item{round.n}{number of digits after comma, default is \code{5}.}

\item{parms.coding}{parmeters coding: none or log2, default: \code{none}.}

\item{fminlower}{minimal value for the function Q.func, default is 0.}

\item{flag.find.one.min}{do you want to find one min value and stop? Default: \code{FALSE}.}

\item{show}{show plots of DIRECT algorithm: none, final iteration, all iterations. Default: \code{none}.}

\item{N}{define the number of start points depending on the dimensionality of the parameter space.}

\item{maxevals}{the maximum number of DIRECT function evaluations, default: 500.}

\item{EI.eps}{the convergence threshold for the expected improvement between fmin and the updated point}

\item{min.iter}{the minimus iterations after the initial \code{N} iterations.}

\item{parallel}{If \code{TRUE}, use parallel foreach to fit each fold except parallelizing each lambda for the tree-lasso methods. If \code{c(TRUE,TRUE)}, use parallel foreach to fit each fold and each lambda.}

\item{modelList}{detailed information of the search process}

\item{verbose}{print the middle search information, default is \code{TRUE}.}

\item{seed}{random seed}

\item{search.path}{save the visited points, default is \code{FALSE}.}

\item{espilon}{the convergence shreshold for the function \code{Q.func}, default is 0.01.}
}
\description{
Finds an optimal solution for the \code{Q.func} function.
}
\details{
IPFStructPenalty
}
\references{
Frohlich, H. & Zell, A. (2005). \emph{Efficient Parameter Selection for Support Vector Machines in Clas- sification and Regression via Model-Based Global Optimization.} Proceedings of the International Joint Conference of Neural Networks, pp 1431-1438.

Sill, M., Hielscher, T., Becker, N. & Zucknick, M. (2014).\emph{c060: Extended Inference with Lasso and elastic net Regularized Cox and Generalized Linear methods.} Journal of Statistical Software, 62(5):1-22.
}
